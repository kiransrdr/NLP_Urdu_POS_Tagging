{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFbVnmtv1KYD",
        "outputId": "2f25a4e5-9833-48cd-e5dd-353ae87520e1"
      },
      "source": [
        "\n",
        "def logits_to_tokens(sequences, index):\n",
        "    token_sequences = []\n",
        "    for categorical_sequence in sequences:\n",
        "        token_sequence = []\n",
        "        for categorical in categorical_sequence:\n",
        "            token_sequence.append(index[np.argmax(categorical)])\n",
        "\n",
        "        token_sequences.append(token_sequence)\n",
        "\n",
        "    return token_sequences\n",
        "\n",
        "\n",
        "def to_categorical(sequences, categories):\n",
        "    cat_sequences = []\n",
        "    for s in sequences:\n",
        "        cats = []\n",
        "        for item in s:\n",
        "            cats.append(np.zeros(categories))\n",
        "            cats[-1][item] = 1.0\n",
        "        cat_sequences.append(cats)\n",
        "    return np.array(cat_sequences)\n",
        "\n",
        "\n",
        "def get_words(sentences):\n",
        "    words = set([])\n",
        "    for sentence in sentences:\n",
        "        for word in sentence:\n",
        "            words.add(word)\n",
        "    return words\n",
        "\n",
        "\n",
        "def get_tags(sentences_tags):\n",
        "    tags = set([])\n",
        "    for tag in sentences_tags:\n",
        "        for t in tag:\n",
        "            tags.add(t)\n",
        "    return tags\n",
        "\n",
        "\n",
        "def get_train_sentences_x(train_sentences, word2index):\n",
        "    train_sentences_x = []\n",
        "    for sentence in train_sentences:\n",
        "        sentence_index = []\n",
        "        for word in sentence:\n",
        "            try:\n",
        "                sentence_index.append(word2index[word])\n",
        "            except KeyError:\n",
        "                sentence_index.append(word2index['-OOV-'])\n",
        "\n",
        "        train_sentences_x.append(sentence_index)\n",
        "    return train_sentences_x\n",
        "\n",
        "\n",
        "def get_test_sentences_x(test_sentences, word2index):\n",
        "    test_sentences_x = []\n",
        "    for sentence in test_sentences:\n",
        "        sentence_index = []\n",
        "        for word in sentence:\n",
        "            try:\n",
        "                sentence_index.append(word2index[word])\n",
        "            except KeyError:\n",
        "                sentence_index.append(word2index['-OOV-'])\n",
        "        test_sentences_x.append(sentence_index)\n",
        "    return test_sentences_x\n",
        "\n",
        "\n",
        "def get_train_tags_y(train_tags, tag2index):\n",
        "    train_tags_y = []\n",
        "    for tags in train_tags:\n",
        "        train_tags_y.append([tag2index[t] for t in tags])\n",
        "    return train_tags_y\n",
        "\n",
        "\n",
        "def get_test_tags_y(test_tags, tag2index):\n",
        "    test_tags_y = []\n",
        "    for tags in test_tags:\n",
        "        test_tags_y.append([tag2index[t] for t in tags])\n",
        "    return test_tags_y\n",
        "import codecs\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "\n",
        "tagged_sentences = codecs.open(\"/content/drive/MyDrive/Colab Notebooks/pos.txt\", encoding=\"utf-8\").readlines()\n",
        "print(tagged_sentences[0])\n",
        "print(\"Tagged sentences: \", len(tagged_sentences))\n",
        "sentences, sentence_tags = [], []\n",
        "import ast\n",
        "for tagged_sentence in tagged_sentences:\n",
        "    sentence, tags = zip(*ast.literal_eval(tagged_sentence))\n",
        "    sentences.append(np.array(sentence))\n",
        "    sentence_tags.append(np.array(tags))\n",
        "(train_sentences, test_sentences, train_tags, test_tags) = train_test_split(sentences, sentence_tags, test_size=0.1)\n",
        "# print(train_sentences)\n",
        "words = get_words(train_sentences)\n",
        "tags = get_tags(train_tags)\n",
        "print(tags)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('اشتتیاق', 'NN'), ('اور', 'CC'), ('ملائکہ', 'NN'), ('ہی', 'I'), ('ببانگِ', 'NN'), ('دہل', 'PN'), ('موجود', 'ADJ'), ('ہیں', 'VB'), ('اس', 'PD'), ('وقت', 'NN'), ('تو', 'I'), ('۔', 'SM')]\n",
            "\n",
            "Tagged sentences:  4\n",
            "{'ADJ', 'TA', 'CC', 'AA', 'P', 'I', 'SM', 'PM', 'PN', 'NEG', 'AKP', 'CA', 'PD', 'VB', 'NN'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ke4h_W-5_MqI"
      },
      "source": [
        "word2index = {w: i + 2 for i, w in enumerate(list(words))}\n",
        "word2index['-PAD-'] = 0\n",
        "word2index['-OOV-'] = 1\n",
        "\n",
        "tag2index = {t: i + 1 for i, t in enumerate(list(tags))}\n",
        "tag2index['-PAD-'] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eY1USPnN_N6a",
        "outputId": "ea54303c-755e-4fc2-fee1-181c9af4f246"
      },
      "source": [
        "train_sentences_x = get_train_sentences_x(train_sentences, word2index)\n",
        "test_sentences_x = get_test_sentences_x(test_sentences, word2index)\n",
        "print(tag2index)\n",
        "train_tags_y = get_train_tags_y(train_tags, tag2index)\n",
        "test_tags_y = get_test_tags_y(test_tags, tag2index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'ADJ': 1, 'TA': 2, 'CC': 3, 'AA': 4, 'P': 5, 'I': 6, 'SM': 7, 'PM': 8, 'PN': 9, 'NEG': 10, 'AKP': 11, 'CA': 12, 'PD': 13, 'VB': 14, 'NN': 15, '-PAD-': 0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xr9I6Ktf_VPe"
      },
      "source": [
        "MAX_LENGTH = len(max(train_sentences_x, key=len))\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "train_sentences_x = pad_sequences(train_sentences_x, maxlen=MAX_LENGTH, padding='post')\n",
        "test_sentences_x = pad_sequences(test_sentences_x, maxlen=MAX_LENGTH, padding='post')\n",
        "train_tags_y = pad_sequences(train_tags_y, maxlen=MAX_LENGTH, padding='post')\n",
        "test_tags_y = pad_sequences(test_tags_y, maxlen=MAX_LENGTH, padding='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzLmCLM8_ecG",
        "outputId": "3b3851f3-a907-4854-9f5f-ee27b46192ab"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Activation, Dense\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.InputLayer(input_shape=(MAX_LENGTH,)))\n",
        "model.add(tf.keras.layers.Embedding(len(word2index), 128))\n",
        "model.add(Dense(128))\n",
        "model.add(Dense(len(tag2index)))\n",
        "model.add(Activation('softmax'))\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(0.001),\n",
        "              metrics=['accuracy'])\n",
        "history = model.fit(train_sentences_x, to_categorical(train_tags_y, len(tag2index)), batch_size=32, epochs=10,\n",
        "                    validation_split=0.2).history\n",
        "# model.save(\"../models/mlp.h5\")\n",
        "\n",
        "scores = model.evaluate(test_sentences_x, to_categorical(test_tags_y, len(tag2index)))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.7732 - accuracy: 0.0333 - val_loss: 2.7893 - val_accuracy: 0.0333\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 2.7381 - accuracy: 0.1000 - val_loss: 2.7880 - val_accuracy: 0.0333\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.7032 - accuracy: 0.5833 - val_loss: 2.7867 - val_accuracy: 0.0667\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.6681 - accuracy: 0.6500 - val_loss: 2.7853 - val_accuracy: 0.0667\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 2.6328 - accuracy: 0.6667 - val_loss: 2.7840 - val_accuracy: 0.0667\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.5969 - accuracy: 0.7333 - val_loss: 2.7826 - val_accuracy: 0.0333\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.5604 - accuracy: 0.8000 - val_loss: 2.7812 - val_accuracy: 0.0333\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.5231 - accuracy: 0.8000 - val_loss: 2.7798 - val_accuracy: 0.0333\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 2.4848 - accuracy: 0.8333 - val_loss: 2.7783 - val_accuracy: 0.0333\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.4453 - accuracy: 0.8333 - val_loss: 2.7768 - val_accuracy: 0.0333\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.3363 - accuracy: 0.7000\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 30, 128)           7552      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 30, 128)           16512     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 30, 16)            2064      \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 30, 16)            0         \n",
            "=================================================================\n",
            "Total params: 26,128\n",
            "Trainable params: 26,128\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}